# Partitioning

For larger datasets, replication alone may not be sufficient to meet query performance requirements. In such cases,
performance can be further improved by splitting data across multiple **partitions** (also known as **shards**, 
**regions**, **vnodes**, etc.).

Each partition typically holds a defined subset of the data. These partitions can be placed on different nodes, 
allowing the workload to be distributed across multiple pieces of hardware. As a result, queries that access only a 
single partition can be processed directly by that partition, improving efficiency and scalability.

Partitions are usually combined with replication, where each node stores data for more than one partition. Although 
each piece of data logically belongs to a single partition, it is replicated across multiple nodes to provide fault 
tolerance. In a leader–follower setup, this enables a node to act as the leader for some partitions while serving as a 
follower for others.


## Partitioning of Key-Value Data

The main goal of partitioning is to evenly distribute data and load across all partitions (1). If the partitioning 
scheme does not spread data or load evenly, the partitions become **skewed**, which reduces the effectiveness and 
performance of partitioning. In extreme cases, when a single partition handles significantly more data or traffic than
others, that partition is referred to as a **hotspot**.
{.annotate}

1. Theoretically, 10 nodes should be able to handle 10× the data volume and read/write throughput.

To avoid these scenarios, it is necessary to choose an appropriate **partitioning key**. The partitioning key should
allow the system to directly identify which partition a query belongs to, while also ensuring that data and load are
distributed proportionally across partitions.

Some commonly used partitioning schemes are described below. Assume the system uses a key–value data model, where the 
key uniquely identifies each value.

1. **Key Range**: Data is divided across partitions based on a continuous range of keys. The boundaries of these ranges
   are used to determine the target partition, allowing direct routing of requests if the partition-to-node mapping is 
   known. The ranges do not need to be uniform; they can be adjusted to ensure an even distribution of data, especially
   when some keys are associated with more data than others.

    However, this approach can lead to hotspots for certain access patterns. For example, if the key is a timestamp 
    and most queries target recent timestamps, a small number of partitions may receive most of the load. One way to 
    mitigate this issue is to group data using a prefix along with the timestamp (for example, `userId_timestamp`).

2. **Hash Key**: Using a good deterministic hash function helps evenly distribute keys across partitions, reducing skew 
   and hotspots. After hashing, partitions are typically defined over ranges of hashed values. However, hashing removes
   the natural ordering of keys, which negatively impacts the performance of range queries.

!!! note ""
    Cassandra uses a hybrid approach. The partitioning key is composed of multiple columns, where only the first column
    is used to determine the partition, and the remaining columns are used to sort data within the partition. This 
    enables efficient range queries within a single partition and is especially useful for modeling one-to-many 
    relationships such as `(user_id, timestamp)`.

---

Here is a **validated and clarified rewrite** that keeps the **original wording and intent**, while improving grammar, flow, and technical precision. The tone and structure are aligned with the earlier partitioning sections.

---

For highly skewed workloads where most reads and writes target the same key, the partitioning schemes described above
are often insufficient. For example, in social media systems, data associated with celebrities typically receives
far more activity than data for regular users.

One way to mitigate hotspots in such scenarios is to handle the problem at the **application layer**. Since the 
application is aware of which keys are hot, it can append or prepend a short random prefix to the key. This allows 
the same logical key to be distributed across multiple partitions, thereby spreading write load more evenly.

While this approach helps distribute writes uniformly, it negatively impacts read performance. Reads must now query
multiple partitions and aggregate the results to reconstruct the full data for the key.

Because this technique requires maintaining additional metadata and coordination, it is typically applied only to keys
with very high write throughput. Keys with low or moderate throughput can continue to use the standard partitioning 
scheme, avoiding the overhead of managing extra bookkeeping.

## Partitioning and Secondary Indexes

The schemes discussed above work well for the **primary index key**, where all reads and writes that use the primary
key can be routed directly to their respective partitions. However, the situation is different for 
**secondary indexes**. Records do not need to be uniquely identifiable by a secondary key, and secondary keys cannot be
directly mapped to partitions in a way that guarantees uniform data distribution.

As a result, secondary indexes introduce additional challenges in partitioned systems. The two most common approaches 
for using secondary indexes with partitions are described below.

1. **Partitioning Secondary Indexes by Document**: In this approach, the secondary index only describes the data stored
   within its own partition. For this reason, it is also referred to as a **local index**. Since a given secondary key
   may exist in any partition, queries using the secondary index must be sent to all partitions in parallel, a process 
   commonly known as **scatter/gather**.

    Because of this, read queries using secondary indexes are generally less performant. Despite this limitation, local 
    secondary indexes are widely used in production systems. A common recommendation is to partition data in such a way
    that secondary index queries can be satisfied from a single partition whenever possible.

2. **Partitioning Secondary Indexes by Term**: This approach, also known as a **global index**, builds a secondary 
   index that spans data across all partitions. To avoid creating a bottleneck, the global index itself must be
   partitioned across multiple nodes rather than stored on a single node.

    The partitioning strategy for the global index can be independent of the primary data partitioning. For example, 
    the index can be partitioned by the secondary key using either a range-based or hash-based scheme. This 
    significantly improves read performance for secondary index queries, as the global index knows exactly which
    partitions contain the relevant data.

    The trade-off is that writes become more expensive. A single write operation may require updates to multiple 
    partitions in order to keep the global index consistent, increasing write latency and complexity.


## Rebalancing Partitions


As a system evolves, changes in access patterns and data distribution require **rebalancing partitions** to keep load 
evenly distributed across nodes. The minimum requirements for rebalancing are that it should cause **no downtime** 
and should move **only the minimum amount of data** necessary to achieve an even distribution of data and load.

To support this, there are several approaches for assigning partitions to nodes.

!!! note "Don't use hash mod N for rebalancing"
    Using `hash(key) mod N` for partitioning causes most keys to move to different partitions whenever `N` 
    (the number of nodes) changes. This makes rebalancing extremely expensive. Instead, use approaches that move only
    the necessary data when nodes are added or removed.

1. **Fixed Number of Partitions**: In this approach, the system creates significantly more partitions than nodes, with
   each node owning multiple partitions. When a new node joins the cluster, it can take ownership of a few partitions
   from existing nodes to rebalance the system. Since data transfer takes time, the original partitions continue 
   serving read and write requests during the transition.

    This approach also allows assigning more partitions to more powerful nodes, enabling them to handle greater load.

    Most systems using this strategy keep the total number of partitions fixed from the beginning to simplify 
    operational complexity. However, each partition introduces management overhead, and having too many partitions can
    negatively impact efficiency and performance. Choosing the right number of partitions upfront is challenging: if 
    the number is too low, data growth increases partition size, making rebalancing more expensive; if it is too high,
    operational overhead increases.

2. **Dynamic Partitioning**: Databases such as HBase use dynamic key-range partitioning. When the data in a partition 
   exceeds a certain threshold, it is split into two partitions. Conversely, when data shrinks below a threshold, 
   partitions can be merged. After a split or merge, partitions are redistributed across nodes to maintain an even 
   load distribution. 

    One advantage of this approach is that it eliminates the need to manually define partition boundaries upfront, 
    which can be difficult to correct later if chosen poorly. The number of partitions automatically adapts to the dataset size.

    A drawback is that, at the beginning, a newly created database typically operates on a single node because it 
    starts empty. Some databases (such as HBase and MongoDB) mitigate this by supporting **pre-splitting**, which 
    allows users to define an initial set of partitions in advance.

3. **Partitioning Proportionally to Nodes**: This approach, used by Cassandra, keeps a fixed number of partitions per 
   node. As the dataset grows, partition sizes increase proportionally while the number of partitions per node 
   remains constant. This helps keep the size of each partition relatively stable.

    When a new node is added, it randomly selects a fixed number of partitions from existing nodes, splits them, and 
    takes ownership of one half of each split. Although this random selection may appear unfair, it converges toward 
    an even load distribution when applied across a large number of partitions. Because partition boundaries are chosen
    randomly, this approach requires hash-based partitioning.

### Operations: Automatic or Manual Rebalancing

Fully automating rebalancing can be convenient, as it reduces operational and maintenance overhead. However, it can 
also be unpredictable, which may be expensive and harmful to other nodes if not handled carefully (1). When combined 
with automatic failure detection, this unpredictability can worsen system stability.
{.annotate}

1. Rerouting requests and copying data can easily overload network and disk resources.

For example, a node that becomes temporarily overloaded due to rebalancing activity may be mistakenly marked as failed
by the failure detection mechanism. This can trigger the provisioning of a new node, which itself requires rebalancing. 
The additional rebalancing load can further stress the system, potentially causing a cascading failure that affects
the entire cluster.

For these reasons, it is important to keep a **human-in-the-loop** for rebalancing operations.


## Request Routing

How does a client know which node to connect to, especially when partitions are frequently rebalanced across nodes? 
This problem is typically solved using **service discovery** mechanisms. Common approaches include:

- Allowing the client to send requests to any node. If the node owns the required partition, it processes the request; 
  otherwise, it forwards the request to the appropriate node.
- Using a middleware layer that is aware of partitions and their associated nodes, and routes requests accordingly.
- Making the client itself aware of the partitioning scheme and the corresponding node assignments.

To stay informed about changes in partition-to-node mappings, most systems rely on a separate coordination service 
such as ZooKeeper. Each node registers with this coordination component before joining the cluster. The service keeps
partition metadata up to date and notifies other components (such as routing middleware) when partitions are reassigned.

This approach is used by systems such as HBase, SolrCloud, Kafka, and MongoDB. In contrast, systems like Cassandra 
and Riak use a **gossip protocol**, where nodes exchange state information among themselves so that each node is aware 
of partition ownership and can forward incoming requests to the correct node.

!!! note "Parallel Query Execution"
    Massively Parallel Processing (MPP) relational databases, commonly used for analytics, support complex queries that 
    involve multiple expensive operations. An MPP query optimizer breaks such queries into a series of stages and
    partitions, many of which can be executed in parallel. Efficient parallel execution of data warehouse queries is a
    specialized topic and receives significant attention due to the importance of analytics workloads to businesses.
